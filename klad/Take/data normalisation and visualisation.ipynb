{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA NORMALISATION\n",
    "This notebook will contain functions that normalise temperature and rainfall data.\n",
    "The data will be normalised on a yearly basis.\n",
    "Also we will attempt to visualise the data via the pandas module in graphs and tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import cell\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pyexcel as pyex\n",
    "import xlrd\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSEUDOCODE and TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir:  /home/take/DataProcessing1/datasets/original datasets/rainfall & temp/All countries\n"
     ]
    }
   ],
   "source": [
    "print('dir: ', os.getcwd())\n",
    "#print('')\n",
    "#!ls\n",
    "#print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise\n",
    "The goal of the next function is to normalise the temperature and rainfall data over the period of 1991 - 2015 on a yearly basis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NORMALISEER DATA VAN ALLE LANDEN\n",
    "\n",
    "## scale the values on yearly basis\n",
    "\n",
    "def feature_scaling(values):\n",
    "    \n",
    "    normalised_values = []\n",
    "    \n",
    "    X_min = values.min()\n",
    "    X_maxmin = values.max() - values.min()\n",
    "    \n",
    "    for value in values:\n",
    "        \n",
    "        normalised_values.append(float((float(value)-float(X_min))/float(X_maxmin)))\n",
    "    \n",
    "    return normalised_values\n",
    "\n",
    "\n",
    "def normalise():\n",
    "    print('hello world')\n",
    "    \n",
    "    normalised_values = feature_scaling(values)\n",
    "    \n",
    "    \n",
    "    ## FILE INPUT: .CSV\n",
    "\n",
    "    ## FILE OUTPUT: .CSV\n",
    "    \n",
    "## data = pd.read_csv('tas_pr_1991_2015_AC.csv')\n",
    "\n",
    "## print(list(data.columns.values))\n",
    "\n",
    "## for year in data.loc[:, '\\tYear']:\n",
    "    \n",
    "    \n",
    "    \n",
    "## print(data.loc[:, '\\tYear'])\n",
    "## data.loc[:,'pr']\n",
    "## data.loc[:,'tas']\n",
    "## data.loc[:,'Month']\n",
    "## data.loc[:,'Country']\n",
    "\n",
    "\n",
    "\n",
    "## input a country name\n",
    "\n",
    "## return normalised rainfall     data, via .loc[] command\n",
    "##        normalised temperature  data, via .loc[] command\n",
    "\n",
    "## HOW\n",
    "## collect data via .loc[] command, iterate over the years\n",
    "## append yearly data of rainfall into list\n",
    "## append yearly data of temperature in to list\n",
    "\n",
    "## find all necessary values for the feature scaling formulae\n",
    "\n",
    "##      X_val-min = X_val - X_min\n",
    "##      X_max-min = X_max - X_min\n",
    "\n",
    "##      X_max = largest value in list\n",
    "##      X_min = lowest value in list\n",
    "##      X_val = val to be normalised\n",
    "\n",
    "## after normalisation -> annualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "normalise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise\n",
    "The goal of the next function is to visualise the data in charts/graphs/tables sorted by country\n",
    "<nr>Input:   country\n",
    "<br>Output:  charts/graphs/tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualise data for countries\n",
    "\n",
    "def visualise():\n",
    "    print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "visualise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise normalised data pr and tas in a country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "def get_input():\n",
    "    country = input(\"Please input one of the above abbreviations: \")\n",
    "    return country\n",
    "\n",
    "# bool member check\n",
    "def check_country(country, country_abbrv):\n",
    "    \n",
    "    if country_abbrv.count(country):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# function to get all country abbreviations\n",
    "def country_list():\n",
    "    \n",
    "    data = pd.read_csv('tas_pr_1991_2015_AC.csv')\n",
    "    \n",
    "    country_abbrv = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "\n",
    "        for info in row:\n",
    "\n",
    "            if type(info) == str and country_abbrv.count(info) != 1:\n",
    "                country_abbrv.append(info)\n",
    "    \n",
    "    return country_abbrv \n",
    "    \n",
    "    \n",
    "def visualise_country():\n",
    "    print(\"Useable country abbreviations: \")\n",
    "    print('')\n",
    "    \n",
    "    country_abbrv = country_list()\n",
    "    \n",
    "    ## print correct abbreviations\n",
    "    for abbrv in country_abbrv:\n",
    "        print(abbrv)\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    country = str(get_input())\n",
    "    \n",
    "    #make sure the input is in the .csv\n",
    "    while not check_country(country, country_abbrv):\n",
    "        country = str(get_input())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useable country abbreviations: \n",
      "\n",
      "GIN\n",
      "RWA\n",
      "LBR\n",
      "LBN\n",
      "ETH\n",
      "ZAR\n",
      "DJI\n",
      "SEN\n",
      "CPV\n",
      "BFA\n",
      "PAK\n",
      "MRT\n",
      "MWI\n",
      "MOZ\n",
      "BDI\n",
      "SDN\n",
      "TZA\n",
      "ZMB\n",
      "MLI\n",
      "AFG\n",
      "LSO\n",
      "ZWE\n",
      "IRQ\n",
      "NGA\n",
      "KEN\n",
      "SOM\n",
      "NER\n",
      "SLE\n",
      "IRN\n",
      "UGA\n",
      "CMR\n",
      "CAF\n",
      "MDG\n",
      "\n",
      "Please input one of the above abbreviations: kokodes\n",
      "Please input one of the above abbreviations: swastika\n",
      "Please input one of the above abbreviations: penis\n",
      "Please input one of the above abbreviations: GIN\n"
     ]
    }
   ],
   "source": [
    "visualise_country()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
data normalisation and visualisation.ipynb
